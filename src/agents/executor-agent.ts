import { parseJsonSafe } from "@/utils/clean-json";
import openaiClient from "@/services/openAIClient";
import type { LoadedFile } from "@/types/loaded-file";
import { saveDebugPrompt } from "@/utils/debug-prompt";
import type { ExecutorOutput } from "@/types/executor-output";
import { buildExecutorPrompt } from "@/prompts/build-executor-prompt";

/**
 * Input parameters for the Executor Agent.
 */
type ExecutorAgentParams = {
    /** The JSON string of the plan generated by the Planner Agent. */
    planJson: string;
    /** Concatenated project documentation serving as context. */
    projectDocs: string;
    /** List of actual files loaded from the repository that the agent can read/modify. */
    files: LoadedFile[];
};

/**
 * Runs the Executor Agent
 * 
 * This agent is responsible for taking the detailed plan from the Planner Agent and the
 * relevant source files, then generating the actual code modifications (unified diffs).
 * 
 * Process:
 * 1. Constructs a prompt with the plan, docs, and file contents.
 * 2. Calls OpenAI to generate the implementation.
 * 3. Parses the output JSON into a structured object containing diffs.
 * 
 * @param params - The input parameters containing plan, context, and files.
 * @returns The structured output containing unified diffs and summary.
 * 
 * @example
 * {
 *   summary: "Added login validation logic",
 *   confidence: 1.0,
 *   modifications: [
 *     { path: "src/auth.ts", diff: "--- src/auth.ts\n+++ src/auth.ts..." }
 *   ],
 *   missingInformation: []
 * }
 */
export async function runExecutorAgent(
    params: ExecutorAgentParams
): Promise<ExecutorOutput> {
    const prompt = buildExecutorPrompt({
        plan: params.planJson,
        projectDocs: params.projectDocs,
        files: params.files.map(f => ({
            path: f.path,
            content: f.content,
        })),
    });

    saveDebugPrompt(prompt, `/executor/executor-input`)

    console.log("Calling OpenAI API...");
    const response = await openaiClient.chat.completions.create({
        model: "gpt-4.1-mini",
        messages: [{ role: "user", content: prompt }],
        temperature: 0,
    }, {
        timeout: 120000
    });
    console.log("âœ“ Received response from OpenAI");

    const content = response.choices[0].message?.content ?? "{}";

    console.log("Saving debug prompt...");
    saveDebugPrompt(content, `/executor/executor-content-output`)

    const parsed = parseJsonSafe<ExecutorOutput>(content);
    return parsed;
}
